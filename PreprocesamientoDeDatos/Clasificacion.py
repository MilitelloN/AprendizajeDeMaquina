# -*- coding: utf-8 -*-
"""PreProcesamiento-Clasificacion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1btBylXSccz78fjFzoHIWGLqIxQ14vbJR
"""

import pandas as pd
from scipy.io import arff

# Cargar el archivo ARFF
data, meta = arff.loadarff("/content/PhishingWebsitesClassificationDataset.arff")
df = pd.DataFrame(data)

# Convertir byte-strings a enteros
df_clean = df.map(lambda x: int(x.decode("utf-8")) if isinstance(x, bytes) else x)

# Identificar columnas categóricas (todas lo son)
categorical_vars = df_clean.select_dtypes(include="int").columns.tolist()
numerical_vars = []  # No hay variables continuas

# Verificar valores únicos
for col in categorical_vars:
    print(f"{col}: {df_clean[col].unique()}")

"""Visualizacion de datos y valores que puede tener cada columna"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Función para graficar distribución de variables
def plot_distributions(dataframe, cols, target='Result', n_cols=3):
    n_rows = int(np.ceil(len(cols) / n_cols))
    plt.figure(figsize=(n_cols * 5, n_rows * 4))
    for i, col in enumerate(cols, 1):
        plt.subplot(n_rows, n_cols, i)
        sns.countplot(data=dataframe, x=col, hue=target, palette='Set2')
        plt.title(f'Distribución de {col}')
        plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

# Ejemplo de uso
selected_columns = ['URL_Length', 'SSLfinal_State', 'web_traffic', 'Result']
plot_distributions(df_clean, selected_columns[:-1], target='Result')

# Matriz de correlación (entre valores -1, 0, 1)
plt.figure(figsize=(12, 10))
sns.heatmap(df_clean.corr(), cmap='coolwarm', annot=False)
plt.title("Matriz de Correlación")
plt.show()

# Verificar valores faltantes
missing_data = df_clean.isnull().sum()
print("Valores faltantes:\n", missing_data[missing_data > 0])

# Verificar outliers (valores fuera de -1, 0, 1)
outliers_check = {
    col: df_clean[~df_clean[col].isin([-1, 0, 1])][col].unique()
    for col in categorical_vars
}
outliers = {k: v.tolist() for k, v in outliers_check.items() if len(v) > 0}
print("Outliers encontrados:\n", outliers)

# Tratamiento de datos faltantes (no hay en este dataset, pero ejemplo)
df_final = df_clean.dropna()

# Verificar integridad post-tratamiento
print("Forma final del dataset:", df_final.shape)